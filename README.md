# Ex.No.3-Scenario-Based Report Development Utilizing Diverse Prompting Techniques

### DATE:23.05.2025                                                                         
### REGISTER NUMBER : 212222040096
## Aim:
To design an AI-powered chatbot that assists customers in resolving issues related to product troubleshooting, order tracking, and general inquiries. The chatbot should handle various customer queries efficiently while maintaining a conversational and user-friendly tone. In this experiment, we will employ different prompt patterns to guide the development process of the chatbot, ranging from basic task-oriented prompts to more complex, persona-driven prompts. Case study 1 with Straightforward Prompts, Tabular Format Prompting and Preceding Question Prompting  

## Explanation - Any one use case from Unit 5 and generate the report for that with the unit 2 Prompt type
## Procedure:
## 1.	Define the Scenario and Use Case:
### Scenario:
The manufacturing industry is looking to reduce manual monitoring and increase efficiency through automation. The system will utilize IoT devices and embedded controllers to automate equipment, monitor performance, and enable predictive maintenance. The goal is to streamline the production process, minimize downtime, and enhance energy efficiency.
Target Audience:
Manufacturing companies, specifically in sectors like automotive, electronics, and food processing, where automation can significantly improve productivity.


### Main Objectives:

•	Improve production efficiency by 30%.
•	Minimize machinery downtime with predictive maintenance.
•	Enable real-time monitoring and remote control of manufacturing systems.
•	Reduce energy consumption by optimizing processes.
 
## 2.	Identify Prompt Patterns for Each Design Aspect:
### Idea Generation Prompts:

•	Prompt: “What features can be incorporated into the automation system to optimize production and reduce downtime?” Generated Ideas:
•	Sensors for real-time monitoring of equipment performance.
•	Predictive maintenance alerts to anticipate equipment failures.
•	Energy usage optimization by automating the switching of machines on/off based on demand.
•	Cloud-based dashboards for remote monitoring and control of machinery.

### Persona and Context Prompts:

•	Prompt: “What should the user interface and control system convey to the operators and managers?” Generated Context:
•	The user interface should be intuitive and provide real-time data on machine performance, energy usage, and alerts.
•	The system should convey reliability and ease of use, with minimal training required for operators.

## AI TOOLS UTILIZED
• ChatGPT (OpenAI)
• GitHub Copilot (OpenAI + GitHub)
• Google Gemini (Google DeepMind)
## OBJECTIVES
• To investigate how alterations in prompt structures affect AI-generated narrative
output.
• To perform a comparative stylistic and thematic analysis across AI tools.
• To assess how different LLMs (Large Language Models) process and respond to
structured vs. unstructured prompts.
## PROCEDURE
### Step 1: Scenario Definition
A uniform scenario was established for all prompt experiments:
"Write a story about a girl who becomes a full-stack developer, overcomes imposter
syndrome, and ends up launching a tech startup that changes her life."
### Step 2: Prompt Engineering Patterns
Three prompt types were formulated to maintain semantic consistency while varying
syntactic and structural approaches:
1. Straightforward Prompting – Direct narrative instruction.
2. Tabular Format Prompting – Structured prompts using defined story elements in
tabular form.
3. Preceding Question Prompting – A segmented interrogative approach followed by
synthesis.
### Step 3: AI Model Interaction
Each prompt design was deployed independently across ChatGPT, Copilot, and Gemini
interfaces. Output narratives were documented and categorized based on prompt type and
model used.
### Step 4: Output Evaluation Metrics
Generated stories were compared using the following parameters:
• Linguistic tone and creative articulation
• Narrative architecture (plot structure and progression)
• Thematic integrity and consistency
• Story depth, emotional flow, and character development
## PROMPT PATTERN DESIGNS & MODEL RESPONSES
### 1. STRAIGHTFORWARD PROMPTING
 Prompt:
"Write a story about a girl who becomes a full-stack developer, overcomes imposter
syndrome, and ends up launching a tech startup that changes her life."
Length Constraint: ~300 words

![image](https://github.com/user-attachments/assets/d1746741-154d-4fd9-a583-34dc683eaae2)

### 2. TABULAR FORMAT PROMPTING
Prompt Style:
Structured breakdown using story components like Main Character, Journey, Conflict,
Climax, Resolution, and Tone.

![image](https://github.com/user-attachments/assets/7d30d695-c3d4-4a72-85c5-fe45b2d55c9e)

### 3. PRECEDING QUESTION PROMPTING
Prompt:
A series of 5 guiding questions was provided (e.g., “Who is the main character?”, “What
challenge does she face?”), followed by an instruction to generate a narrative using the
answers.

![image](https://github.com/user-attachments/assets/5bc03796-62f1-4342-9dd1-6a48833bc506)

### RESULTS AND ANALYSIS
Observations:

![image](https://github.com/user-attachments/assets/3bfd6cd1-1651-404c-baaa-808bffb3e348)

### CONCLUSION
This experimental study highlights the behavioral divergence in narrative generation
across three AI platforms under different prompting methodologies:
• Straightforward prompts yielded the most complete and cohesive stories across all
tools.
• Tabular prompts facilitated structurally organized responses, with ChatGPT showing
notable proficiency.
• Preceding question prompts revealed the greatest disparity—ChatGPT and Copilot
managed inference and synthesis, while Gemini required user-fed data points for
continuation.
Key Insight: The design and structure of prompts significantly influence the semantic
processing, narrative style, and completion behavior of generative AI tools.
NOTE
This comparative report does not serve as a benchmark or ranking of AI models but instead
aims to observe and interpret variances in natural language understanding and
generation behavior based on prompt engineering strategies.





# Result:
Thus the Prompts were exected succcessfully.

